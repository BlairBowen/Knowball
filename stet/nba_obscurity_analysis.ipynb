{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfca959d",
   "metadata": {},
   "source": [
    "\n",
    "# NFL Player Obscurity Score Calculator 🏈\n",
    "\n",
    "This notebook computes *obscurity scores* for NFL players using a combination of heuristics and deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206b3e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 15:04:51.533197: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742756691.545731   29226 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742756691.550254   29226 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-23 15:04:51.563772: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TF warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_obscurity_scores(csv_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Compute obscurity scores for NFL players using deep learning.\n",
    "\n",
    "    This function:\n",
    "    1. Loads NFL player data\n",
    "    2. Processes and normalizes relevant features\n",
    "    3. Creates a custom deep learning model\n",
    "    4. Computes obscurity scores (100 = most obscure, 0 = least obscure)\n",
    "    5. Returns dataframe with added obscurity scores\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to CSV file with NFL player data\n",
    "        output_file (str, optional): Path to save results. If None, doesn't save.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Player data with computed obscurity scores\n",
    "    \"\"\"\n",
    "    # 1. Load and prepare the data\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Clean the data\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # 2. Feature extraction & engineering\n",
    "\n",
    "    # A. Basic visibility features\n",
    "    # Pageviews - direct measure of visibility (inverse relation to obscurity)\n",
    "    if 'Pageviews' in df.columns:\n",
    "        df['pageviews_factor'] = df['Pageviews']\n",
    "    else:\n",
    "        # If no pageviews data, estimate from games played and awards\n",
    "        df['pageviews_factor'] = df['G'] * 5000\n",
    "\n",
    "    # B. Accomplishment features\n",
    "    # Combine awards\n",
    "    df['awards_count'] = df['MVP'] + df['OPOY'] + df['DPOY'] + \\\n",
    "        df['OROY'] + df['DROY'] + df['AP1'] + df['SB']\n",
    "\n",
    "    # C. Position-specific performance metrics\n",
    "    # For QBs\n",
    "    df['qb_career_value'] = 0\n",
    "    qb_mask = df['Pos'] == 'QB'\n",
    "    if qb_mask.any():\n",
    "        df.loc[qb_mask, 'qb_career_value'] = (\n",
    "            df.loc[qb_mask, 'PaYds'] * 0.1 +\n",
    "            df.loc[qb_mask, 'PaTD'] * 5 +\n",
    "            df.loc[qb_mask, 'QBWin'] * 10 +\n",
    "            df.loc[qb_mask, 'GWD'] * 15\n",
    "        )\n",
    "\n",
    "    # For RBs\n",
    "    df['rb_career_value'] = 0\n",
    "    rb_mask = df['Pos'] == 'RB'\n",
    "    if rb_mask.any():\n",
    "        df.loc[rb_mask, 'rb_career_value'] = (\n",
    "            df.loc[rb_mask, 'RuYds'] * 0.2 +\n",
    "            df.loc[rb_mask, 'RuTD'] * 10 +\n",
    "            df.loc[rb_mask, 'RecYds'] * 0.15\n",
    "        )\n",
    "\n",
    "    # For WRs/TEs\n",
    "    df['wr_te_career_value'] = 0\n",
    "    wr_te_mask = (df['Pos'] == 'WR') | (df['Pos'] == 'TE')\n",
    "    if wr_te_mask.any():\n",
    "        df.loc[wr_te_mask, 'wr_te_career_value'] = (\n",
    "            df.loc[wr_te_mask, 'RecYds'] * 0.2 +\n",
    "            df.loc[wr_te_mask, 'RecTD'] * 10 +\n",
    "            df.loc[wr_te_mask, 'Rec'] * 0.5\n",
    "        )\n",
    "\n",
    "    # For defensive players\n",
    "    df['def_career_value'] = 0\n",
    "    def_mask = df['Pos'].isin(['DE', 'DT', 'LB', 'CB', 'S'])\n",
    "    if def_mask.any():\n",
    "        df.loc[def_mask, 'def_career_value'] = (\n",
    "            df.loc[def_mask, 'Solo'] * 1 +\n",
    "            df.loc[def_mask, 'Ast'] * 0.5 +\n",
    "            df.loc[def_mask, 'TFL'] * 3 +\n",
    "            df.loc[def_mask, 'IntD'] * 15 +\n",
    "            df.loc[def_mask, 'FF'] * 10\n",
    "        )\n",
    "\n",
    "    # Combine all position values into a single career value metric\n",
    "    career_value_cols = ['qb_career_value', 'rb_career_value',\n",
    "                         'wr_te_career_value', 'def_career_value']\n",
    "    df['career_value'] = df[career_value_cols].max(axis=1)\n",
    "\n",
    "    # D. Career longevity and volume\n",
    "    df['games_factor'] = df['G'] / df['G'].max() if df['G'].max() > 0 else 0\n",
    "    df['fantasy_factor'] = df['FantPts'] / \\\n",
    "        df['FantPts'].max() if df['FantPts'].max() > 0 else 0\n",
    "\n",
    "    # 3. Calculate the base obscurity score using key metrics\n",
    "\n",
    "    # A. Extract normalized key metrics (higher = less obscure)\n",
    "    # Reverse the logic: higher values in these metrics = lower obscurity\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    # Normalize each metric to 0-1 range\n",
    "    if df['pageviews_factor'].max() > 0:\n",
    "        metrics['pageviews'] = df['pageviews_factor'] / \\\n",
    "            df['pageviews_factor'].max()\n",
    "    else:\n",
    "        metrics['pageviews'] = 0\n",
    "\n",
    "    # Normalizing assuming 10 awards is maximum\n",
    "    metrics['awards'] = df['awards_count'] / 10\n",
    "    metrics['career_value'] = df['career_value'] / \\\n",
    "        df['career_value'].max() if df['career_value'].max() > 0 else 0\n",
    "    metrics['games'] = df['games_factor']\n",
    "    metrics['fantasy'] = df['fantasy_factor']\n",
    "\n",
    "    # B. Calculate the visibility score (inverse of obscurity)\n",
    "    # Weight the metrics based on importance\n",
    "    weights = {\n",
    "        'pageviews': 0.65,\n",
    "        'awards': 0.1,\n",
    "        'career_value': 0.225,\n",
    "        'games': 0.025,\n",
    "        'fantasy': 0.00\n",
    "    }\n",
    "\n",
    "    visibility_score = (\n",
    "        metrics['pageviews'] * weights['pageviews'] +\n",
    "        metrics['awards'] * weights['awards'] +\n",
    "        metrics['career_value'] * weights['career_value'] +\n",
    "        metrics['games'] * weights['games'] +\n",
    "        metrics['fantasy'] * weights['fantasy']\n",
    "    )\n",
    "\n",
    "    # C. Convert visibility to obscurity (100 = most obscure, 0 = least obscure)\n",
    "    df['obscurity_score_basic'] = 100 * (1 - visibility_score)\n",
    "\n",
    "    # 4. Deep Learning Enhancement\n",
    "    # Use a neural network to capture more complex relationships\n",
    "\n",
    "    # A. Prepare features for deep learning\n",
    "    feature_cols = [\n",
    "        'pageviews_factor', 'awards_count', 'career_value',\n",
    "        'G', 'GS', 'FantPts'\n",
    "    ]\n",
    "\n",
    "    categorical_cols = ['Pos']\n",
    "\n",
    "    # Create position-specific performance columns for better feature representation\n",
    "    for pos in df['Pos'].unique():\n",
    "        # Skip if position is missing/nan\n",
    "        if pd.isna(pos):\n",
    "            continue\n",
    "\n",
    "        pos_mask = df['Pos'] == pos\n",
    "        if pos_mask.sum() > 0:\n",
    "            # For each position, add relevant stat columns\n",
    "            if pos == 'QB':\n",
    "                df[f'{pos}_PaYds_per_G'] = df['PaYds'] / \\\n",
    "                    df['G'].where(df['G'] > 0, 1)\n",
    "                df[f'{pos}_PaTD_per_G'] = df['PaTD'] / \\\n",
    "                    df['G'].where(df['G'] > 0, 1)\n",
    "                feature_cols.extend(\n",
    "                    [f'{pos}_PaYds_per_G', f'{pos}_PaTD_per_G'])\n",
    "            elif pos == 'RB':\n",
    "                df[f'{pos}_RuYds_per_G'] = df['RuYds'] / \\\n",
    "                    df['G'].where(df['G'] > 0, 1)\n",
    "                df[f'{pos}_RuTD_per_G'] = df['RuTD'] / \\\n",
    "                    df['G'].where(df['G'] > 0, 1)\n",
    "                feature_cols.extend(\n",
    "                    [f'{pos}_RuYds_per_G', f'{pos}_RuTD_per_G'])\n",
    "            elif pos in ['WR', 'TE']:\n",
    "                df[f'{pos}_RecYds_per_G'] = df['RecYds'] / \\\n",
    "                    df['G'].where(df['G'] > 0, 1)\n",
    "                df[f'{pos}_RecTD_per_G'] = df['RecTD'] / \\\n",
    "                    df['G'].where(df['G'] > 0, 1)\n",
    "                feature_cols.extend(\n",
    "                    [f'{pos}_RecYds_per_G', f'{pos}_RecTD_per_G'])\n",
    "\n",
    "    # Fill any NaNs created during the calculation\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # Select features and preprocess\n",
    "    X = df[feature_cols + categorical_cols]\n",
    "\n",
    "    # Create preprocessing pipeline with sparse output for categorical features\n",
    "    numerical_transformer = StandardScaler()\n",
    "\n",
    "    # Use sparse output for OneHotEncoder to save memory\n",
    "    categorical_transformer = OneHotEncoder(\n",
    "        handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, feature_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ],\n",
    "        sparse_threshold=0  # Force dense output from the transformer\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # B. Build and train the model\n",
    "    # We'll use the basic obscurity score as a starting point\n",
    "    # and refine it with the neural network\n",
    "    initial_obscurity = df['obscurity_score_basic'].values\n",
    "\n",
    "    # Define the model with memory optimization\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(X_processed.shape[1],)),\n",
    "        layers.Dense(32, activation='relu', use_bias=True),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(16, activation='relu', use_bias=True),\n",
    "        layers.Dense(1, activation='sigmoid')  # Output between 0 and 1\n",
    "    ])\n",
    "\n",
    "    # Use a memory-efficient optimizer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    # Train the model to learn from the initial obscurity scores\n",
    "    # This helps capture complex non-linear relationships\n",
    "\n",
    "    # Set up callbacks to handle warnings\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Suppress TensorFlow warnings during training\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TF warnings\n",
    "\n",
    "    # Train with memory-optimized settings\n",
    "    model.fit(\n",
    "        X_processed,\n",
    "        initial_obscurity / 100,  # Scale to 0-1 for training\n",
    "        epochs=30,  # Reduced epochs\n",
    "        batch_size=8,  # Increased batch size for better memory efficiency\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Make predictions and convert back to 0-100 scale\n",
    "    refined_obscurity = model.predict(X_processed).flatten() * 100\n",
    "\n",
    "    # Combine initial and refined scores (giving more weight to refined)\n",
    "    df['obscurity_score'] = 0.3 * \\\n",
    "        df['obscurity_score_basic'] + 0.7 * refined_obscurity\n",
    "    \n",
    "    # Custom adjustments based on position\n",
    "    position_adjustments = {\n",
    "        'QB': 0.85,  # Reduce obscurity by 15% (more visible)\n",
    "        'RB': 1.0,   # No change\n",
    "        'WR': 0.95,  # Reduce obscurity by 5%\n",
    "        'TE': 1.05,  # Slightly increase (less visible)\n",
    "        'DE': 1.1,   # More obscure\n",
    "        'DT': 1.15,\n",
    "        'LB': 1.05,\n",
    "        'CB': 1.0,\n",
    "        'S': 1.1,\n",
    "        # Add more positions as needed\n",
    "    }\n",
    "\n",
    "    df['obscurity_score'] = df.apply(\n",
    "        lambda row: row['obscurity_score'] * position_adjustments.get(row['Pos'], 1.0),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 5. Apply business rules and adjustments\n",
    "\n",
    "    # A. Award winners should have lower obscurity\n",
    "    # Super Bowl winners, MVPs, etc. are well-known\n",
    "    award_winners = df['awards_count'] > 0\n",
    "    if award_winners.any():\n",
    "        df.loc[award_winners, 'obscurity_score'] *= 0.8  # Reduce obscurity by 20%\n",
    "\n",
    "    # B. Long careers lead to more visibility\n",
    "    long_careers = df['G'] > 100\n",
    "    if long_careers.any():\n",
    "        df.loc[long_careers, 'obscurity_score'] *= 0.9  # Reduce obscurity by 10%\n",
    "\n",
    "    # C. Recent Rookie of the Year winners get more attention\n",
    "    rookies = (df['OROY'] > 0) | (df['DROY'] > 0)\n",
    "    if rookies.any():\n",
    "        df.loc[rookies, 'obscurity_score'] *= 0.85  # Reduce obscurity by 15%\n",
    "\n",
    "    # D. Clean up final scores\n",
    "    # Ensure scores are within 0-100 range\n",
    "    df['obscurity_score'] = df['obscurity_score'].clip(0, 100)\n",
    "\n",
    "    # E. Transform the distribution to be more normal\n",
    "    # First, calculate mean and standard deviation of current scores\n",
    "    mean_score = df['obscurity_score'].mean()\n",
    "    std_score = df['obscurity_score'].std()\n",
    "\n",
    "    # If standard deviation is too small, set a minimum value\n",
    "    std_score = max(std_score, 10)\n",
    "\n",
    "    # Apply transformation to create more of a normal distribution\n",
    "    # This uses a logistic function to spread out the values\n",
    "    from scipy import stats\n",
    "\n",
    "    # Convert to z-scores first\n",
    "    z_scores = (df['obscurity_score'] - mean_score) / std_score\n",
    "\n",
    "    # Apply sigmoid transformation to spread values more evenly\n",
    "    transformed_scores = 1 / (1 + np.exp(-z_scores))\n",
    "\n",
    "    # Scale back to 0-100 range with better spread\n",
    "    # Adjust these parameters to control the shape of the distribution\n",
    "    min_target = 5    # Minimum obscurity score\n",
    "    max_target = 95   # Maximum obscurity score\n",
    "    range_target = max_target - min_target\n",
    "\n",
    "    df['obscurity_score_normalized'] = min_target + \\\n",
    "        range_target * transformed_scores\n",
    "\n",
    "    # Apply a second transformation to improve normality\n",
    "    # Use percentile rank method to create a more uniform distribution first\n",
    "    percentile_ranks = df['obscurity_score_normalized'].rank(pct=True)\n",
    "\n",
    "    # Then transform to normal distribution using inverse normal CDF\n",
    "    from scipy.stats import norm\n",
    "    df['obscurity_score'] = norm.ppf(percentile_ranks) * 15 + 50\n",
    "\n",
    "    # Clip values to ensure they stay in 0-100 range\n",
    "    df['obscurity_score'] = df['obscurity_score'].clip(0, 100)\n",
    "\n",
    "    # Round to 2 decimal places\n",
    "    df['obscurity_score'] = df['obscurity_score'].round(2)\n",
    "\n",
    "    # 6. Create a scaled version (0-100 scale to 0-50 scale)\n",
    "    df['obscurity_score_scaled'] = (df['obscurity_score'] * 0.5).round(2)\n",
    "\n",
    "    # 7. Save the results if output file provided\n",
    "    if output_file:\n",
    "        # Select relevant columns for output\n",
    "        output_df = df.copy()\n",
    "\n",
    "        # Drop intermediate calculation columns\n",
    "        cols_to_drop = [\n",
    "            'pageviews_factor', 'awards_count', 'qb_career_value',\n",
    "            'rb_career_value', 'wr_te_career_value', 'def_career_value',\n",
    "            'career_value', 'games_factor', 'fantasy_factor',\n",
    "            'obscurity_score_basic'\n",
    "        ]\n",
    "\n",
    "        # Also drop position-specific columns we created\n",
    "        pos_cols = [col for col in output_df.columns if any(\n",
    "            f'{pos}_' in col for pos in df['Pos'].unique())]\n",
    "        cols_to_drop.extend(pos_cols)\n",
    "\n",
    "        # Drop columns that exist\n",
    "        cols_to_drop = [\n",
    "            col for col in cols_to_drop if col in output_df.columns]\n",
    "        output_df = output_df.drop(columns=cols_to_drop)\n",
    "\n",
    "        # Save to CSV\n",
    "        output_df.sort_values('obscurity_score', ascending=False).to_csv(output_file, index=False)\n",
    "\n",
    "    # 8. Return the dataframe with obscurity scores\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d726c5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>All_Star</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>2P</th>\n",
       "      <th>...</th>\n",
       "      <th>TOV_PerGame</th>\n",
       "      <th>PF_PerGame</th>\n",
       "      <th>PTS_PerGame</th>\n",
       "      <th>Obscurity_Score</th>\n",
       "      <th>Obscurity_Score_Scaled</th>\n",
       "      <th>visibility_score</th>\n",
       "      <th>performance_score</th>\n",
       "      <th>obscurity_score</th>\n",
       "      <th>obscurity_score_normalized</th>\n",
       "      <th>obscurity_score_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>37369.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>858</td>\n",
       "      <td>104</td>\n",
       "      <td>206</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>1.544118</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>97.886640</td>\n",
       "      <td>135.092316</td>\n",
       "      <td>0.037973</td>\n",
       "      <td>0.121105</td>\n",
       "      <td>11.65</td>\n",
       "      <td>39.81</td>\n",
       "      <td>19.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>61452.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>52</td>\n",
       "      <td>139</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.074074</td>\n",
       "      <td>4.962963</td>\n",
       "      <td>97.533862</td>\n",
       "      <td>130.102759</td>\n",
       "      <td>0.039446</td>\n",
       "      <td>0.126659</td>\n",
       "      <td>12.17</td>\n",
       "      <td>40.99</td>\n",
       "      <td>20.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>130402.0</td>\n",
       "      <td>650</td>\n",
       "      <td>587</td>\n",
       "      <td>0</td>\n",
       "      <td>17161</td>\n",
       "      <td>3423</td>\n",
       "      <td>5539</td>\n",
       "      <td>3423</td>\n",
       "      <td>...</td>\n",
       "      <td>1.069231</td>\n",
       "      <td>2.361538</td>\n",
       "      <td>12.072308</td>\n",
       "      <td>92.295267</td>\n",
       "      <td>73.440784</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0.328692</td>\n",
       "      <td>31.41</td>\n",
       "      <td>66.68</td>\n",
       "      <td>33.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>301712.0</td>\n",
       "      <td>157</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3643</td>\n",
       "      <td>434</td>\n",
       "      <td>971</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165605</td>\n",
       "      <td>1.847134</td>\n",
       "      <td>6.821656</td>\n",
       "      <td>95.031591</td>\n",
       "      <td>99.341260</td>\n",
       "      <td>0.053901</td>\n",
       "      <td>0.250372</td>\n",
       "      <td>23.69</td>\n",
       "      <td>57.22</td>\n",
       "      <td>28.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>37505.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>98.478621</td>\n",
       "      <td>143.870884</td>\n",
       "      <td>0.037960</td>\n",
       "      <td>0.113090</td>\n",
       "      <td>10.88</td>\n",
       "      <td>39.25</td>\n",
       "      <td>19.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Team  Pageviews    G   GS  All_Star     MP    FG  \\\n",
       "0           0  Atlanta Hawks    37369.0   68    1         0    858   104   \n",
       "1           1  Atlanta Hawks    61452.0   27    0         0    320    52   \n",
       "2           2  Atlanta Hawks   130402.0  650  587         0  17161  3423   \n",
       "3           3  Atlanta Hawks   301712.0  157   64         0   3643   434   \n",
       "4           4  Atlanta Hawks    37505.0   11    0         0    120    11   \n",
       "\n",
       "    FGA    2P  ...  TOV_PerGame  PF_PerGame  PTS_PerGame  Obscurity_Score  \\\n",
       "0   206   100  ...     0.352941    1.544118     3.823529        97.886640   \n",
       "1   139    39  ...     0.666667    1.074074     4.962963        97.533862   \n",
       "2  5539  3423  ...     1.069231    2.361538    12.072308        92.295267   \n",
       "3   971   321  ...     1.165605    1.847134     6.821656        95.031591   \n",
       "4    38    11  ...     1.090909    1.363636     2.363636        98.478621   \n",
       "\n",
       "   Obscurity_Score_Scaled  visibility_score  performance_score  \\\n",
       "0              135.092316          0.037973           0.121105   \n",
       "1              130.102759          0.039446           0.126659   \n",
       "2               73.440784          0.044281           0.328692   \n",
       "3               99.341260          0.053901           0.250372   \n",
       "4              143.870884          0.037960           0.113090   \n",
       "\n",
       "   obscurity_score  obscurity_score_normalized  obscurity_score_scaled  \n",
       "0            11.65                       39.81                   19.91  \n",
       "1            12.17                       40.99                   20.49  \n",
       "2            31.41                       66.68                   33.34  \n",
       "3            23.69                       57.22                   28.61  \n",
       "4            10.88                       39.25                   19.63  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Path to your NFL player data (update as needed)\n",
    "input_file = \"nba_locked.csv\"\n",
    "# input_file = \"nfl_locked.csv\"\n",
    "output_file = \"nba_with_obscurity.csv\"\n",
    "\n",
    "# Compute obscurity scores\n",
    "result_df = compute_obscurity_scores(input_file, output_file)\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe74282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Obscure Players:\n",
      "                    Player                Team     G  obscurity_score  \\\n",
      "16              Trae Young       Atlanta Hawks   445            47.11   \n",
      "100          Anthony Davis    Dallas Mavericks   773            43.30   \n",
      "132      Russell Westbrook      Denver Nuggets  1204            43.28   \n",
      "121           Nikola Jokić      Denver Nuggets   711            42.75   \n",
      "134        Cade Cunningham     Detroit Pistons   176            42.60   \n",
      "377            Joel Embiid  Philadelphia 76ers   446            42.55   \n",
      "49             LaMelo Ball   Charlotte Hornets   211            42.46   \n",
      "269  Giannis Antetokounmpo     Milwaukee Bucks   827            42.38   \n",
      "454             Chris Paul   San Antonio Spurs  1313            42.26   \n",
      "457      Victor Wembanyama   San Antonio Spurs   107            42.25   \n",
      "\n",
      "     obscurity_score_scaled  \n",
      "16                    50.00  \n",
      "100                   46.64  \n",
      "132                   44.95  \n",
      "121                   43.90  \n",
      "134                   43.13  \n",
      "377                   42.51  \n",
      "49                    41.99  \n",
      "269                   41.54  \n",
      "454                   41.15  \n",
      "457                   40.79  \n",
      "\n",
      "Top 5 Least Obscure Players:\n",
      "                 Player                    Team     G  obscurity_score  \\\n",
      "142      Daniss Jenkins         Detroit Pistons     3             0.00   \n",
      "127  Michael Foster Jr.          Denver Nuggets     1             0.00   \n",
      "288        Jaylen Clark  Minnesota Timberwolves     3             0.38   \n",
      "222        LeBron James      Los Angeles Lakers  1529             0.43   \n",
      "504       Jaylen Martin      Washington Wizards     3             0.83   \n",
      "300      Tristen Newton  Minnesota Timberwolves     6             0.92   \n",
      "452  JaQuori McLaughlin       San Antonio Spurs     4             0.98   \n",
      "393       Jalen Bridges            Phoenix Suns     4             1.09   \n",
      "449     Harrison Ingram       San Antonio Spurs     1             1.16   \n",
      "223        Bronny James      Los Angeles Lakers    10             1.22   \n",
      "\n",
      "     obscurity_score_scaled  \n",
      "142                    4.34  \n",
      "127                    4.34  \n",
      "288                    6.10  \n",
      "222                    6.87  \n",
      "504                    7.49  \n",
      "300                    8.01  \n",
      "452                    8.46  \n",
      "393                    8.85  \n",
      "449                    9.21  \n",
      "223                    9.53  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Top 5 Most Obscure Players:\")\n",
    "most_obscure = result_df.sort_values('obscurity_score', ascending=False).head(10)\n",
    "print(most_obscure[['Player', 'Team', 'G', 'obscurity_score', 'obscurity_score_scaled']])\n",
    "\n",
    "print(\"\\nTop 5 Least Obscure Players:\")\n",
    "least_obscure = result_df.sort_values('obscurity_score').head(10)\n",
    "print(least_obscure[['Player', 'Team', 'G', 'obscurity_score', 'obscurity_score_scaled']])\n",
    "\n",
    "# print(\"\\nMid Obscure Players (around rank 800-850):\")\n",
    "# mid_obscure = result_df.sort_values('obscurity_score')\n",
    "# mid_obscure = mid_obscure[800:850]\n",
    "# print(mid_obscure[['Player', 'Pos', 'Team', 'G', 'obscurity_score', 'obscurity_score_scaled']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33696b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "n, bins, patches = plt.hist(result_df['obscurity_score'], bins=30,\n",
    "                            color='skyblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "mu = result_df['obscurity_score'].mean()\n",
    "sigma = result_df['obscurity_score'].std()\n",
    "x = np.linspace(0, 100, 100)\n",
    "y = ((1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-0.5 *\n",
    "     ((x - mu) / sigma) ** 2)) * len(result_df) * (bins[1] - bins[0])\n",
    "plt.plot(x, y, 'r--', linewidth=2)\n",
    "\n",
    "plt.title('Distribution of NFL Player Obscurity Scores', fontsize=16)\n",
    "plt.xlabel('Obscurity Score (100 = Most Obscure)', fontsize=12)\n",
    "plt.ylabel('Number of Players', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "stats_text = f\"Mean: {mu:.2f}\\nStd Dev: {sigma:.2f}\\nMedian: {result_df['obscurity_score'].median():.2f}\"\n",
    "plt.text(0.75, 0.8, stats_text, transform=plt.gca().transAxes,\n",
    "         bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
